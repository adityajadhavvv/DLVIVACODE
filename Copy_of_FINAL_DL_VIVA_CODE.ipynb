{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **EXPT 1 ALL GATE**"
      ],
      "metadata": {
        "id": "ppevOKfzboRA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6e4ZmefbnrO",
        "outputId": "7410e775-7f99-4e2a-e5ae-ed3e22395a40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND Gate:\n",
            "0 AND 0 = 0\n",
            "0 AND 1 = 0\n",
            "1 AND 0 = 0\n",
            "1 AND 1 = 1\n",
            "\n",
            "OR Gate:\n",
            "0 OR 0 = 0\n",
            "0 OR 1 = 1\n",
            "1 OR 0 = 1\n",
            "1 OR 1 = 1\n",
            "\n",
            "NOR Gate:\n",
            "0 NOR 0 = 1\n",
            "0 NOR 1 = 0\n",
            "1 NOR 0 = 0\n",
            "1 NOR 1 = 0\n",
            "\n",
            "NAND Gate:\n",
            "0 NAND 0 = 1\n",
            "0 NAND 1 = 1\n",
            "1 NAND 0 = 1\n",
            "1 NAND 1 = 0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# McCulloch-Pitts neuron model implementation\n",
        "class McCullochPittsNeuron:\n",
        "    def __init__(self, weights, threshold):\n",
        "        self.weights = np.array(weights)\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def activate(self, inputs):\n",
        "        weighted_sum = np.dot(inputs, self.weights)\n",
        "        if weighted_sum >= self.threshold:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "# Implementing logic gates using McCulloch-Pitts neurons\n",
        "def AND_gate(inputs):\n",
        "    weights = [1, 1]\n",
        "    threshold = 2\n",
        "    neuron = McCullochPittsNeuron(weights, threshold)\n",
        "    return neuron.activate(inputs)\n",
        "\n",
        "def OR_gate(inputs):\n",
        "    weights = [1, 1]\n",
        "    threshold = 1\n",
        "    neuron = McCullochPittsNeuron(weights, threshold)\n",
        "    return neuron.activate(inputs)\n",
        "\n",
        "def NOR_gate(inputs):\n",
        "    weights = [-1, -1]\n",
        "    threshold = -0.5\n",
        "    neuron = McCullochPittsNeuron(weights, threshold)\n",
        "    return neuron.activate(inputs)\n",
        "\n",
        "def NAND_gate(inputs):\n",
        "    gate1 = AND_gate(inputs)\n",
        "    return int(not gate1)\n",
        "\n",
        "# Testing the logic gates\n",
        "print(\"AND Gate:\")\n",
        "print(\"0 AND 0 =\", AND_gate([0, 0]))\n",
        "print(\"0 AND 1 =\", AND_gate([0, 1]))\n",
        "print(\"1 AND 0 =\", AND_gate([1, 0]))\n",
        "print(\"1 AND 1 =\", AND_gate([1, 1]))\n",
        "\n",
        "print(\"\\nOR Gate:\")\n",
        "print(\"0 OR 0 =\", OR_gate([0, 0]))\n",
        "print(\"0 OR 1 =\", OR_gate([0, 1]))\n",
        "print(\"1 OR 0 =\", OR_gate([1, 0]))\n",
        "print(\"1 OR 1 =\", OR_gate([1, 1]))\n",
        "\n",
        "print(\"\\nNOR Gate:\")\n",
        "print(\"0 NOR 0 =\", NOR_gate([0, 0]))\n",
        "print(\"0 NOR 1 =\", NOR_gate([0, 1]))\n",
        "print(\"1 NOR 0 =\", NOR_gate([1, 0]))\n",
        "print(\"1 NOR 1 =\", NOR_gate([1, 1]))\n",
        "\n",
        "print(\"\\nNAND Gate:\")\n",
        "print(\"0 NAND 0 =\", NAND_gate([0, 0]))\n",
        "print(\"0 NAND 1 =\", NAND_gate([0, 1]))\n",
        "print(\"1 NAND 0 =\", NAND_gate([1, 0]))\n",
        "print(\"1 NAND 1 =\", NAND_gate([1, 1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EXPT 2 XOR MULTIPLE **"
      ],
      "metadata": {
        "id": "pRv90yTNcPG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the unit step function\n",
        "def unit_step(v):\n",
        "    return 1 if v >= 0 else 0\n",
        "\n",
        "# Define the perceptron model\n",
        "def perceptron(x, w, b):\n",
        "    v = np.dot(w, x) + b\n",
        "    return unit_step(v)\n",
        "\n",
        "# Define the NOT logic function\n",
        "def NOT_logic(x):\n",
        "    return perceptron(x, w=-1, b=0.5)\n",
        "\n",
        "# Define the AND logic function\n",
        "def AND_logic(x):\n",
        "    return perceptron(x, w=np.array([1, 1]), b=-1.5)\n",
        "\n",
        "# Define the OR logic function\n",
        "def OR_logic(x):\n",
        "    return perceptron(x, w=np.array([1, 1]), b=-0.5)\n",
        "\n",
        "# Define the XOR logic function using other logic functions\n",
        "def XOR_logic(x):\n",
        "    y1 = AND_logic(x)\n",
        "    y2 = OR_logic(x)\n",
        "    y3 = NOT_logic(y1)\n",
        "    final_x = np.array([y2, y3])\n",
        "    return AND_logic(final_x)\n",
        "\n",
        "# Testing the perceptron model\n",
        "test_cases = [(0, 1), (1, 1), (0, 0), (1, 0)]\n",
        "\n",
        "for test_case in test_cases:\n",
        "    x = np.array(test_case)\n",
        "    print(\"XOR({}, {}) = {}\".format(*test_case, XOR_logic(x)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESXrjVJIc7DK",
        "outputId": "f9b76c6a-2cef-4f8a-ab71-fe96a0d18787"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR(0, 1) = 1\n",
            "XOR(1, 1) = 0\n",
            "XOR(0, 0) = 0\n",
            "XOR(1, 0) = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EXPT 3 fully connected deep neural network with at least 1 hidden layers**"
      ],
      "metadata": {
        "id": "B4d-KU-3eoZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=(784,), activation=\"relu\"))\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compile the model with SGD optimizer\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(optimizer=sgd_optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images.reshape(-1, 784), train_labels, epochs=10, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_images.reshape(-1, 784), test_labels, verbose=0)\n",
        "print(f'Test accuracy: {test_accuracy}')\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(test_images.reshape(-1, 784))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk_if5D3e41A",
        "outputId": "615a33f4-d32d-4560-fd5d-78e6dc84a557"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 256)               200960    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235146 (918.54 KB)\n",
            "Trainable params: 235146 (918.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 11s 5ms/step - loss: 0.7036 - accuracy: 0.7685\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.4828 - accuracy: 0.8319\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.4412 - accuracy: 0.8455\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4151 - accuracy: 0.8555\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3944 - accuracy: 0.8626\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3778 - accuracy: 0.8675\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3642 - accuracy: 0.8727\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3526 - accuracy: 0.8759\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3417 - accuracy: 0.8795\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3319 - accuracy: 0.8824\n",
            "Test accuracy: 0.8658999800682068\n",
            "313/313 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EXPT 4 GRADIENT DESCENT ALL**"
      ],
      "metadata": {
        "id": "8_lZwHT2fA51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "# Load the Fashion MNIST dataset\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=(784,), activation=\"relu\"))\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compile the model with SGD optimizer\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(optimizer=sgd_optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images.reshape(-1, 784), train_labels, epochs=5, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_images.reshape(-1, 784), test_labels, verbose=0)\n",
        "print(f'Test accuracy: {test_accuracy}')\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(test_images.reshape(-1, 784))\n",
        "\n",
        "\n",
        "#mini_batch_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9) model.compile(optimizer=mini_batch_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy']))\n",
        "#momentum_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9) model.compile(optimizer=momentum_optimizer,loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "#nesterov_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True) model.compile(optimizer=nesterov_optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "#adagrad_optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.01) model.compile(optimizer=adagrad_optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "#adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) model.compile(optimizer=adam_optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93UpOKEUfb9l",
        "outputId": "23e5cd74-c2bc-4d53-ff6e-c850703ff44e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 256)               200960    \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235146 (918.54 KB)\n",
            "Trainable params: 235146 (918.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.7011 - accuracy: 0.7693\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4809 - accuracy: 0.8326\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.4353 - accuracy: 0.8475\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4099 - accuracy: 0.8561\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.3903 - accuracy: 0.8612\n",
            "Test accuracy: 0.8476999998092651\n",
            "313/313 [==============================] - 1s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EXPT 5 FORWARD PASS ONLY**"
      ],
      "metadata": {
        "id": "YAOzN34Yflgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Input data\n",
        "input_data = np.array([0.05, 0.1])\n",
        "\n",
        "# Weights for input to hidden layer\n",
        "weights_input_hidden = np.array([[0.15, 0.2], [0.25, 0.3]])\n",
        "\n",
        "# Bias for hidden layer\n",
        "bias_hidden = np.array([0.35, 0.35])\n",
        "\n",
        "# Weights for hidden to output layer\n",
        "weights_hidden_output = np.array([[0.4, 0.45], [0.5, 0.55]])\n",
        "\n",
        "# Bias for output layer\n",
        "bias_output = np.array([0.6, 0.6])\n",
        "\n",
        "# Perform forward pass\n",
        "hidden_inputs = np.dot(input_data, weights_input_hidden) + bias_hidden\n",
        "hidden_outputs = sigmoid(hidden_inputs)\n",
        "\n",
        "output_inputs = np.dot(hidden_outputs, weights_hidden_output) + bias_output\n",
        "output = sigmoid(output_inputs)\n",
        "\n",
        "print(\"Output of the network:\", output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-GQTVZEf6y8",
        "outputId": "83b51e86-e936-4f19-cacc-0eb79becc1ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output of the network: [0.75693192 0.76771788]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EXPT 6 CNN with one convolution layer of filter size 8 and filter size 3 and pool size 2**"
      ],
      "metadata": {
        "id": "ip1m0UZtgM2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "!pip install mnist\n",
        "import mnist\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#training & testing\n",
        "train_images = mnist.train_images()\n",
        "train_labels = mnist.train_labels()\n",
        "test_images = mnist.test_images()\n",
        "test_labels = mnist.test_labels()\n",
        "# Normalize the images.\n",
        "train_images = (train_images / 255) - 0.5\n",
        "test_images = (test_images / 255) - 0.5\n",
        "\n",
        "# Reshape the images.\n",
        "train_images = np.expand_dims(train_images, axis=3)\n",
        "test_images = np.expand_dims(test_images, axis=3)\n",
        "num_filters = 8\n",
        "filter_size = 3\n",
        "pool_size = 2\n",
        "# Build the model.\n",
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "# Compile the model.\n",
        "model.compile(optimizer='adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "# Train the model.\n",
        "model.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=2,\n",
        "  validation_data=(test_images, to_categorical(test_labels)),\n",
        ")\n",
        "model.save_weights('cnn.h5')\n",
        "predictions = model.predict(test_images[:5])\n",
        "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
        "print(test_labels[:5]) # [7, 2, 1, 0, 4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie1_7_5ngNUv",
        "outputId": "637b4536-1779-4b47-ec30-1d877037704d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mnist in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mnist) (1.25.2)\n",
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3429 - accuracy: 0.8996 - val_loss: 0.1901 - val_accuracy: 0.9451\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1653 - accuracy: 0.9531 - val_loss: 0.1328 - val_accuracy: 0.9611\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "[7 2 1 0 4]\n",
            "[7 2 1 0 4]\n"
          ]
        }
      ]
    }
  ]
}